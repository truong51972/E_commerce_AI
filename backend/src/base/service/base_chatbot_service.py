from typing import List, Optional

from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.agents.output_parsers.tools import ToolAgentAction
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage
from pydantic import Field, model_validator, validate_call

from .base_llm_service import BaseLlmService


class BaseChatbotService(BaseLlmService):

    agent_prompt: str = Field(
        default="",
        description="Prompt template for the agent. If not provided, a default prompt will be used.",
    )
    tools: Optional[List[object]] = Field(
        default_factory=list, description="List of tools that the agent can use."
    )
    agent_verbose: bool = Field(
        default=False,
        description="Whether to enable verbose logging for the agent's actions.",
    )

    return_intermediate_steps: bool = Field(
        default=False,
        description="Whether to return the agent's trajectory of intermediate steps at the end in addition to the final output.",
    )

    @model_validator(mode="after")
    def __after_init(self):
        self._prompt = ChatPromptTemplate.from_messages(
            [
                ("system", self.agent_prompt),
                MessagesPlaceholder(
                    variable_name="chat_history"
                ),  # Để duy trì lịch sử trò chuyện
                ("human", "{input}"),  # Đầu vào hiện tại của người dùng
                MessagesPlaceholder(
                    variable_name="agent_scratchpad"
                ),  # Langchain tự quản lý các bước trung gian
            ]
        )

        self._agent = create_tool_calling_agent(
            llm=self._llm,
            tools=self.tools,
            prompt=self._prompt,
        )

        # 5. Tạo AgentExecutor để chạy agent
        self._agent_executor = AgentExecutor(
            agent=self._agent,
            tools=self.tools,
            return_intermediate_steps=self.return_intermediate_steps,
            verbose=self.agent_verbose,  # Hiển thị các bước hoạt động của agent
        )
        return self

    @validate_call
    def run(
        self, user_input: str, chat_history: Optional[List[BaseMessage]] = None
    ) -> list[str, list[str]]:
        """
        run method to process user input and maintain chat history.
        Args:
            user_input (str): The input from the user.
            chat_history (List[BaseMessage]): The history of messages in the chat.
        Returns:
            str: The response generated by the agent.
            List[BaseMessage]: Updated chat history including the new user input and agent response.
        """

        # Call the agent with user input and chat history
        response = self._agent_executor.invoke(
            {"input": user_input, "chat_history": chat_history if chat_history else []}
        )

        # Update chat history with user input and agent response
        if chat_history is not None:
            chat_history.append(HumanMessage(content=user_input))

            # Kiểm tra nếu có các bước trung gian và nó có tool call
            intermediate_steps = response.get("intermediate_steps", None)
            if intermediate_steps:
                for step_action, step_observation in intermediate_steps:
                    if isinstance(step_action, ToolAgentAction):
                        tool_input = step_action.tool_input  # dict các tham số
                        tool_name = step_action.tool  # tên tool
                        tool_message = ToolMessage(
                            content=f"Tool: {tool_name}\nInput: {tool_input}\nOutput: {step_observation}",
                            tool_call_id=step_action.tool_call_id,
                            tool=tool_name,
                            tool_input=tool_input,
                            observation=step_observation,
                        )
                        chat_history.append(tool_message)

            chat_history.append(AIMessage(content=response["output"]))

        return response["output"], chat_history
